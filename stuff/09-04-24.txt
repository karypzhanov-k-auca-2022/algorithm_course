                                            Reward Function

set of Action
set of States/set of observations
Action πolicy (Observation) -> Action

double Reward (Action action, State state, State nextState) {
    double reward = 0;
    if (nextState.isTerminal) {
        reward = 100;
    } else {
        reward = -1;
    }
    return reward;
}

Probability Distribution

double Probability (State s, Action a) {
    double probability = 0;
    if (state.isTerminal) {
        probability = 0;
    } else {
        probability = 1;
    }
    return probability;
}

Rewardsment learning

Markov Decision Processes

Markov Decision Processes (MDPs) are a mathematical framework for modeling
decision-making in situations where outcomes are partly random and partly under the control of a decision maker.
MDPs are useful for studying a wide range of optimization problems solved via dynamic programming and reinforcement learning.

Reversing the MDP
1) Reward Function
2) Set of Action
3) Set of States/set of observations
4) Probability Distribution
5) Discount Factor (γ)

Action πolicy (Observation) -> Action

